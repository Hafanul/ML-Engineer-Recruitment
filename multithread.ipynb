{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "icdBVTP_SX8E"
      },
      "source": [
        "import threading\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "\n",
        "from multiprocessing.pool import ThreadPool\n",
        "from collections import deque\n",
        "\n",
        "#from common import clock, draw_str, StatValue\n",
        "#import video"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_ea0udillf_"
      },
      "source": [
        "# Copyright (c) OpenMMLab. All rights reserved.\n",
        "import os\n",
        "import warnings\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "import cv2\n",
        "\n",
        "from mmpose.apis import (get_track_id, inference_top_down_pose_model,\n",
        "                         init_pose_model, process_mmdet_results,\n",
        "                         vis_pose_tracking_result)\n",
        "from mmpose.datasets import DatasetInfo\n",
        "\n",
        "try:\n",
        "    from mmdet.apis import inference_detector, init_detector\n",
        "    has_mmdet = True\n",
        "except (ImportError, ModuleNotFoundError):\n",
        "    has_mmdet = False\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Visualize the demo images.\n",
        "\n",
        "    Using mmdet to detect the human.\n",
        "    \"\"\"\n",
        "    parser = ArgumentParser()\n",
        "    parser.add_argument('det_config', help='Config file for detection')\n",
        "    parser.add_argument('det_checkpoint', help='Checkpoint file for detection')\n",
        "    parser.add_argument('pose_config', help='Config file for pose')\n",
        "    parser.add_argument('pose_checkpoint', help='Checkpoint file for pose')\n",
        "    parser.add_argument('--video-path', type=str, help='Video path')\n",
        "    parser.add_argument(\n",
        "        '--show',\n",
        "        action='store_true',\n",
        "        default=False,\n",
        "        help='whether to show visualizations.')\n",
        "    parser.add_argument(\n",
        "        '--out-video-root',\n",
        "        default='',\n",
        "        help='Root of the output video file. '\n",
        "        'Default not saving the visualization video.')\n",
        "    parser.add_argument(\n",
        "        '--device', default='cuda:0', help='Device used for inference')\n",
        "    parser.add_argument(\n",
        "        '--det-cat-id',\n",
        "        type=int,\n",
        "        default=1,\n",
        "        help='Category id for bounding box detection model')\n",
        "    parser.add_argument(\n",
        "        '--bbox-thr',\n",
        "        type=float,\n",
        "        default=0.3,\n",
        "        help='Bounding box score threshold')\n",
        "    parser.add_argument(\n",
        "        '--kpt-thr', type=float, default=0.3, help='Keypoint score threshold')\n",
        "    parser.add_argument(\n",
        "        '--use-oks-tracking', action='store_true', help='Using OKS tracking')\n",
        "    parser.add_argument(\n",
        "        '--tracking-thr', type=float, default=0.3, help='Tracking threshold')\n",
        "    parser.add_argument(\n",
        "        '--euro',\n",
        "        action='store_true',\n",
        "        help='Using One_Euro_Filter for smoothing')\n",
        "    parser.add_argument(\n",
        "        '--radius',\n",
        "        type=int,\n",
        "        default=4,\n",
        "        help='Keypoint radius for visualization')\n",
        "    parser.add_argument(\n",
        "        '--thickness',\n",
        "        type=int,\n",
        "        default=1,\n",
        "        help='Link thickness for visualization')\n",
        "\n",
        "    assert has_mmdet, 'Please install mmdet to run the demo.'\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    assert args.show or (args.out_video_root != '')\n",
        "    assert args.det_config is not None\n",
        "    assert args.det_checkpoint is not None\n",
        "\n",
        "    det_model = init_detector(\n",
        "        args.det_config, args.det_checkpoint, device=args.device.lower())\n",
        "    # build the pose model from a config file and a checkpoint file\n",
        "    pose_model = init_pose_model(\n",
        "        args.pose_config, args.pose_checkpoint, device=args.device.lower())\n",
        "\n",
        "    dataset = pose_model.cfg.data['test']['type']\n",
        "    dataset_info = pose_model.cfg.data['test'].get('dataset_info', None)\n",
        "    if dataset_info is None:\n",
        "        warnings.warn(\n",
        "            'Please set `dataset_info` in the config.'\n",
        "            'Check https://github.com/open-mmlab/mmpose/pull/663 for details.',\n",
        "            DeprecationWarning)\n",
        "    else:\n",
        "        dataset_info = DatasetInfo(dataset_info)\n",
        "\n",
        "    cap = cv2.VideoCapture(args.video_path) #video path \n",
        "   \n",
        "# /////////////////////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "    t1 = threading.Thread(target=cap, args=(1,))\n",
        "    t2 = threading.Thread(target=cap, args=(2,))\n",
        "    t3 = threading.Thread(target=cap, args=(3,))\n",
        "    t4 = threading.Thread(target=cap, args=(4,))\n",
        "\n",
        "    # starting thread 1\n",
        "    cap=t1.start()\n",
        "    # starting thread 2\n",
        "    cap=t2.start()\n",
        "    # starting thread 3\n",
        "    cap=t3.start()\n",
        "    # starting thread 4\n",
        "    cap=t4.start()\n",
        "\n",
        "#/////////////////////////////////////////////////////////////////////////////////////\n",
        "    fps = None\n",
        "\n",
        "    assert cap.isOpened(), f'Faild to load video file {args.video_path}'\n",
        "\n",
        "    if args.out_video_root == '':\n",
        "        save_out_video = False\n",
        "    else:\n",
        "        os.makedirs(args.out_video_root, exist_ok=True)\n",
        "        save_out_video = True\n",
        "\n",
        "    if save_out_video:\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
        "                int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        videoWriter = cv2.VideoWriter(\n",
        "            os.path.join(args.out_video_root,\n",
        "                         f'vis_{os.path.basename(args.video_path)}'), fourcc,\n",
        "            fps, size)\n",
        "\n",
        "    # optional\n",
        "    return_heatmap = False\n",
        "\n",
        "    # e.g. use ('backbone', ) to return backbone feature\n",
        "    output_layer_names = None\n",
        "\n",
        "    next_id = 0\n",
        "    pose_results = []\n",
        "    while (cap.isOpened()):\n",
        "        pose_results_last = pose_results\n",
        "\n",
        "        flag, img = cap.read()\n",
        "        if not flag:\n",
        "            break\n",
        "        # test a single image, the resulting box is (x1, y1, x2, y2)\n",
        "        mmdet_results = inference_detector(det_model, img)\n",
        "\n",
        "        # keep the person class bounding boxes.\n",
        "        person_results = process_mmdet_results(mmdet_results, args.det_cat_id)\n",
        "\n",
        "        # test a single image, with a list of bboxes.\n",
        "        pose_results, returned_outputs = inference_top_down_pose_model(\n",
        "            pose_model,\n",
        "            img,\n",
        "            person_results,\n",
        "            bbox_thr=args.bbox_thr,\n",
        "            format='xyxy',\n",
        "            dataset=dataset,\n",
        "            dataset_info=dataset_info,\n",
        "            return_heatmap=return_heatmap,\n",
        "            outputs=output_layer_names)\n",
        "\n",
        "        # get track id for each person instance\n",
        "        pose_results, next_id = get_track_id(\n",
        "            pose_results,\n",
        "            pose_results_last,\n",
        "            next_id,\n",
        "            use_oks=args.use_oks_tracking,\n",
        "            tracking_thr=args.tracking_thr,\n",
        "            use_one_euro=args.euro,\n",
        "            fps=fps)\n",
        "\n",
        "        # show the results\n",
        "        vis_img = vis_pose_tracking_result(\n",
        "            pose_model,\n",
        "            img,\n",
        "            pose_results,\n",
        "            radius=args.radius,\n",
        "            thickness=args.thickness,\n",
        "            dataset=dataset,\n",
        "            dataset_info=dataset_info,\n",
        "            kpt_score_thr=args.kpt_thr,\n",
        "            show=False)\n",
        "\n",
        "        if args.show:\n",
        "            cv2.imshow('Image', vis_img)\n",
        "\n",
        "        if save_out_video:\n",
        "            videoWriter.write(vis_img)\n",
        "\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    if save_out_video:\n",
        "        videoWriter.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}